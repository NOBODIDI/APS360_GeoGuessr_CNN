{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12CdMljWye741naOSbdP3NVSSNnp2KtSC",
      "authorship_tag": "ABX9TyNrWmidJw0DYMo/HlRnCoF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NOBODIDI/APS360_GeoGuessr_NN/blob/main/Creating_Train_Val_Test_Split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useful Links\n",
        "\n",
        "* Pytorch model: https://pytorch.org/vision/stable/models/generated/torchvision.models.googlenet.html#torchvision.models.googlenet\n",
        "*   https://pytorch.org/hub/pytorch_vision_googlenet/\n",
        "*   Background info: https://cs231n.github.io/transfer-learning/\n",
        "*   https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "* Finetuning: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zqh8KJ5nURfR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOL4hoqPs3dY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import time\n",
        "import copy\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading in Data"
      ],
      "metadata": {
        "id": "Mg7MDPJW4cfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting up Data into train-val-test folders (DO NOT RUN)"
      ],
      "metadata": {
        "id": "g6R8yU7Z_LKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data\n",
        "# Data Loading and Splitting\n",
        "\n",
        "train_files_list = []\n",
        "val_files_list = []\n",
        "test_files_list = []\n",
        "files_list = []\n",
        "classes = {}\n",
        "\n",
        "dataset_dirs = [\n",
        "                \"/content/drive/MyDrive/GeoGuessr Train Val Test\"\n",
        "                ]\n",
        "for old_path in dataset_dirs:\n",
        "  for root, dirs, files in os.walk(old_path):\n",
        "      for file in files:\n",
        "\n",
        "          if file.endswith(\".png\"):\n",
        "              files_list.append(os.path.join(root, file))\n",
        "\n",
        "              file_class = (files_list[-1].split('/'))[-2]\n",
        "              if (file_class not in classes):\n",
        "                classes[file_class] = 1\n",
        "              else:\n",
        "                classes[file_class] += 1\n",
        "\n",
        "#print images\n",
        "#lets me count and print the amount of jpeg,jpg,pmg \n",
        "file_count = len(files_list)\n",
        "print(\"We have:\",file_count,\"images\")\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGv5Bbrnlp49",
        "outputId": "9d682289-28d7-4bc5-a7cc-4e6b46a7941c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have: 65198 images\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'114': 1035,\n",
              " '63': 768,\n",
              " '137': 770,\n",
              " '41': 765,\n",
              " '42': 763,\n",
              " '98': 761,\n",
              " '99': 769,\n",
              " '96': 761,\n",
              " '102': 1050,\n",
              " '86': 764,\n",
              " '169': 721,\n",
              " '97': 766,\n",
              " '83': 767,\n",
              " '61': 758,\n",
              " '71': 658,\n",
              " '87': 762,\n",
              " '66': 742,\n",
              " '58': 768,\n",
              " '130': 1042,\n",
              " '22': 754,\n",
              " '134': 1050,\n",
              " '120': 966,\n",
              " '40': 697,\n",
              " '224': 701,\n",
              " '152': 767,\n",
              " '95': 760,\n",
              " '170': 766,\n",
              " '206': 765,\n",
              " '138': 768,\n",
              " '205': 762,\n",
              " '115': 1046,\n",
              " '117': 766,\n",
              " '82': 767,\n",
              " '101': 1049,\n",
              " '149': 727,\n",
              " '76': 755,\n",
              " '59': 758,\n",
              " '65': 716,\n",
              " '153': 764,\n",
              " '135': 767,\n",
              " '100': 1049,\n",
              " '116': 1044,\n",
              " '62': 766,\n",
              " '173': 760,\n",
              " '131': 1042,\n",
              " '60': 752,\n",
              " '80': 766,\n",
              " '136': 769,\n",
              " '39': 695,\n",
              " '69': 755,\n",
              " '132': 760,\n",
              " '68': 760,\n",
              " '84': 768,\n",
              " '57': 765,\n",
              " '118': 1047,\n",
              " '75': 763,\n",
              " '155': 767,\n",
              " '93': 760,\n",
              " '64': 748,\n",
              " '81': 769,\n",
              " '187': 701,\n",
              " '119': 1050,\n",
              " '208': 759,\n",
              " '111': 1042,\n",
              " '79': 758,\n",
              " '151': 763,\n",
              " '133': 1047,\n",
              " '103': 1050,\n",
              " '112': 1040,\n",
              " '85': 769,\n",
              " '44': 765,\n",
              " '188': 759,\n",
              " '150': 736,\n",
              " '78': 759,\n",
              " '23': 766,\n",
              " '113': 1022,\n",
              " '77': 755,\n",
              " '154': 767,\n",
              " '43': 767,\n",
              " '225': 757}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_list = list(classes.keys())\n",
        "print(len(class_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YXXALw0SsH5",
        "outputId": "68d9fa0e-22b5-49b4-87d9-db7472afcd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = 32000\n",
        "split = [0.7,0.15,0.15]  # SPLIT RATIO\n",
        "\n",
        "train_size = int(split[0]*dataset_size)\n",
        "val_size = int(split[1]*dataset_size)\n",
        "test_size = dataset_size - (train_size + val_size)\n",
        "print(\"Train size:\",train_size,\"\\nVal size:\",val_size,\"\\nTest size:\",test_size)\n",
        "\n",
        "# Fixed random seed for reproducible result\n",
        "np.random.seed(1000)\n",
        "\n",
        "indices = list(range(0,dataset_size))\n",
        "train_indices = list(np.random.choice(indices, train_size, replace=False))\n",
        "other_than_train_indices = list(set(indices) - set(train_indices))\n",
        "val_indices = np.random.choice(other_than_train_indices, val_size, replace=False)\n",
        "test_indices = list(set(other_than_train_indices)-set(val_indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX8c3MEfmJD7",
        "outputId": "e5e6d06f-3d4b-411c-f426-4d1a81113864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 22400 \n",
            "Val size: 4800 \n",
            "Test size: 4800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "split_files_list = [ [files_list[i] for i in train_indices], [files_list[i] for i in val_indices], [files_list[i] for i in test_indices] ]\n",
        "\n",
        "destPaths = ['train','val','test']\n",
        "root_path = \"/content/drive/MyDrive/32k_split\"\n",
        "\n",
        "for i in range(len(destPaths)):\n",
        "\n",
        "  destPath = os.path.join(root_path,destPaths[i])\n",
        "  # if destination dir does not exists, create it\n",
        "  if os.path.isdir(destPath) == False:\n",
        "          os.makedirs(destPath)\n",
        "\n",
        "  # iterate over all random files and move them\n",
        "  for file in split_files_list[i]:\n",
        "\n",
        "    file_class = (file.split('/'))[-2]\n",
        "    classPath = os.path.join(destPath,file_class)\n",
        "    if os.path.isdir(classPath) == False:\n",
        "          os.makedirs(classPath)\n",
        "    filePath = os.path.join(classPath,(file.split('/'))[-1])\n",
        "    if os.path.isfile(filePath) == True:\n",
        "      continue\n",
        "    shutil.move(file, classPath)"
      ],
      "metadata": {
        "id": "GGlyO74gdZnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destPaths = ['train','val','test']\n",
        "limits = [280, 60, 60]\n",
        "old_path = \"/content/drive/MyDrive/GeoGuessr Train Val Test\"\n",
        "new_path = \"/content/drive/MyDrive/32k_train_val_test\"\n",
        "\n",
        "i = 0\n",
        "\n",
        "olddestPath = os.path.join(old_path,destPaths[i])\n",
        "destPath = os.path.join(new_path,destPaths[i])\n",
        "# if destination dir does not exists, create it\n",
        "if os.path.isdir(destPath) == False:\n",
        "        os.makedirs(destPath)\n",
        "\n",
        "for j in range(len(class_list)):\n",
        "\n",
        "    oldclassPath = os.path.join(olddestPath,class_list[j])\n",
        "    classPath = os.path.join(destPath,class_list[j])\n",
        "    # if destination dir does not exists, create it\n",
        "    if os.path.isdir(classPath) == False:\n",
        "          os.makedirs(classPath)\n",
        "\n",
        "    k = 0\n",
        "    for root, dirs, files in os.walk(oldclassPath):\n",
        "        for file in files:\n",
        "            if file.endswith(\".png\"):\n",
        "              if (k >= limits[i]):\n",
        "                break\n",
        "              oldfile = os.path.join(oldclassPath,file)\n",
        "              shutil.move(oldfile, classPath)\n",
        "              k+=1\n",
        "        break\n",
        "                \n"
      ],
      "metadata": {
        "id": "WI7JcqfJRxUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1\n",
        "\n",
        "olddestPath = os.path.join(old_path,destPaths[i])\n",
        "destPath = os.path.join(new_path,destPaths[i])\n",
        "# if destination dir does not exists, create it\n",
        "if os.path.isdir(destPath) == False:\n",
        "        os.makedirs(destPath)\n",
        "\n",
        "for j in range(len(class_list)):\n",
        "\n",
        "    oldclassPath = os.path.join(olddestPath,class_list[j])\n",
        "    classPath = os.path.join(destPath,class_list[j])\n",
        "    # if destination dir does not exists, create it\n",
        "    if os.path.isdir(classPath) == False:\n",
        "          os.makedirs(classPath)\n",
        "\n",
        "    k = 0\n",
        "    for root, dirs, files in os.walk(oldclassPath):\n",
        "        for file in files:\n",
        "            if file.endswith(\".png\"):\n",
        "              if (k >= limits[i]):\n",
        "                break\n",
        "              oldfile = os.path.join(oldclassPath,file)\n",
        "              shutil.move(oldfile, classPath)\n",
        "              k+=1\n",
        "        break"
      ],
      "metadata": {
        "id": "DJjvcGdUkgF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 2\n",
        "\n",
        "olddestPath = os.path.join(old_path,destPaths[i])\n",
        "destPath = os.path.join(new_path,destPaths[i])\n",
        "# if destination dir does not exists, create it\n",
        "if os.path.isdir(destPath) == False:\n",
        "        os.makedirs(destPath)\n",
        "\n",
        "for j in range(len(class_list)):\n",
        "\n",
        "    oldclassPath = os.path.join(olddestPath,class_list[j])\n",
        "    classPath = os.path.join(destPath,class_list[j])\n",
        "    # if destination dir does not exists, create it\n",
        "    if os.path.isdir(classPath) == False:\n",
        "          os.makedirs(classPath)\n",
        "\n",
        "    k = 0\n",
        "    for root, dirs, files in os.walk(oldclassPath):\n",
        "        for file in files:\n",
        "            if file.endswith(\".png\"):\n",
        "              if (k >= limits[i]):\n",
        "                break\n",
        "              oldfile = os.path.join(oldclassPath,file)\n",
        "              shutil.move(oldfile, classPath)\n",
        "              k+=1\n",
        "        break"
      ],
      "metadata": {
        "id": "xlN9l5rUkiX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_list = []\n",
        "val_classes = {}\n",
        "tr_list = []\n",
        "tr_classes = {}\n",
        "test_list = []\n",
        "test_classes = {}\n",
        "\n",
        "\n",
        "dataset_dirs = [\"/content/drive/MyDrive/32k_train_val_test\"\n",
        "                ]\n",
        "for old_path in dataset_dirs:\n",
        "  for root, dirs, files in os.walk(old_path):\n",
        "      for file in files:\n",
        "          \n",
        "          if file.endswith(\".png\"):\n",
        "              file_split = root.split('/')[-2]\n",
        "\n",
        "              if (file_split == 'val'):\n",
        "                val_list.append(os.path.join(root, file))\n",
        "\n",
        "                file_class = (val_list[-1].split('/'))[-2]\n",
        "                if (file_class not in val_classes):\n",
        "                  val_classes[file_class] = 1\n",
        "                else:\n",
        "                  val_classes[file_class] += 1\n",
        "\n",
        "              elif (file_split == 'train'):\n",
        "                tr_list.append(os.path.join(root, file))\n",
        "\n",
        "                file_class = (tr_list[-1].split('/'))[-2]\n",
        "                if (file_class not in tr_classes):\n",
        "                  tr_classes[file_class] = 1\n",
        "                else:\n",
        "                  tr_classes[file_class] += 1\n",
        "\n",
        "              elif (file_split == 'test'):\n",
        "                test_list.append(os.path.join(root, file))\n",
        "\n",
        "                file_class = (test_list[-1].split('/'))[-2]\n",
        "                if (file_class not in test_classes):\n",
        "                  test_classes[file_class] = 1\n",
        "                else:\n",
        "                  test_classes[file_class] += 1\n",
        "\n",
        "#print images\n",
        "#lets me count and print the amount of jpeg,jpg,pmg \n",
        "\n",
        "print(\"We have:\",len(tr_list),\"train images\")\n",
        "display(tr_classes)\n",
        "print(\"We have:\",len(val_list),\"val images\")\n",
        "display(val_classes)\n",
        "print(\"We have:\",len(test_list),\"train images\")\n",
        "display(test_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2P_EXSF5pOFk",
        "outputId": "c5cb11f1-eb47-4531-f3aa-cfc430910a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have: 22400 train images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'114': 280,\n",
              " '63': 280,\n",
              " '137': 280,\n",
              " '41': 280,\n",
              " '42': 280,\n",
              " '98': 280,\n",
              " '99': 280,\n",
              " '96': 280,\n",
              " '102': 280,\n",
              " '86': 280,\n",
              " '169': 280,\n",
              " '97': 280,\n",
              " '83': 280,\n",
              " '61': 280,\n",
              " '71': 280,\n",
              " '87': 280,\n",
              " '66': 280,\n",
              " '58': 280,\n",
              " '130': 280,\n",
              " '22': 280,\n",
              " '134': 280,\n",
              " '120': 280,\n",
              " '40': 280,\n",
              " '224': 280,\n",
              " '152': 280,\n",
              " '95': 280,\n",
              " '170': 280,\n",
              " '206': 280,\n",
              " '138': 280,\n",
              " '205': 280,\n",
              " '115': 280,\n",
              " '117': 280,\n",
              " '82': 280,\n",
              " '101': 280,\n",
              " '149': 280,\n",
              " '76': 280,\n",
              " '59': 280,\n",
              " '65': 280,\n",
              " '153': 280,\n",
              " '135': 280,\n",
              " '100': 280,\n",
              " '116': 280,\n",
              " '62': 280,\n",
              " '173': 280,\n",
              " '131': 280,\n",
              " '60': 280,\n",
              " '80': 280,\n",
              " '136': 280,\n",
              " '39': 280,\n",
              " '69': 280,\n",
              " '132': 280,\n",
              " '68': 280,\n",
              " '84': 280,\n",
              " '57': 280,\n",
              " '118': 280,\n",
              " '75': 280,\n",
              " '155': 280,\n",
              " '93': 280,\n",
              " '64': 280,\n",
              " '81': 280,\n",
              " '187': 280,\n",
              " '119': 280,\n",
              " '208': 280,\n",
              " '111': 280,\n",
              " '79': 280,\n",
              " '151': 280,\n",
              " '133': 280,\n",
              " '103': 280,\n",
              " '112': 280,\n",
              " '85': 280,\n",
              " '44': 280,\n",
              " '188': 280,\n",
              " '150': 280,\n",
              " '78': 280,\n",
              " '23': 280,\n",
              " '113': 280,\n",
              " '77': 280,\n",
              " '154': 280,\n",
              " '43': 280,\n",
              " '225': 280}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have: 4800 val images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'114': 60,\n",
              " '63': 60,\n",
              " '137': 60,\n",
              " '41': 60,\n",
              " '42': 60,\n",
              " '98': 60,\n",
              " '99': 60,\n",
              " '96': 60,\n",
              " '102': 60,\n",
              " '86': 60,\n",
              " '169': 60,\n",
              " '97': 60,\n",
              " '83': 60,\n",
              " '61': 60,\n",
              " '71': 60,\n",
              " '87': 60,\n",
              " '66': 60,\n",
              " '58': 60,\n",
              " '130': 60,\n",
              " '22': 60,\n",
              " '134': 60,\n",
              " '120': 60,\n",
              " '40': 60,\n",
              " '224': 60,\n",
              " '152': 60,\n",
              " '95': 60,\n",
              " '170': 60,\n",
              " '206': 60,\n",
              " '138': 60,\n",
              " '205': 60,\n",
              " '115': 60,\n",
              " '117': 60,\n",
              " '82': 60,\n",
              " '101': 60,\n",
              " '149': 60,\n",
              " '76': 60,\n",
              " '59': 60,\n",
              " '65': 60,\n",
              " '153': 60,\n",
              " '135': 60,\n",
              " '100': 60,\n",
              " '116': 60,\n",
              " '62': 60,\n",
              " '173': 60,\n",
              " '131': 60,\n",
              " '60': 60,\n",
              " '80': 60,\n",
              " '136': 60,\n",
              " '39': 60,\n",
              " '69': 60,\n",
              " '132': 60,\n",
              " '68': 60,\n",
              " '84': 60,\n",
              " '57': 60,\n",
              " '118': 60,\n",
              " '75': 60,\n",
              " '155': 60,\n",
              " '93': 60,\n",
              " '64': 60,\n",
              " '81': 60,\n",
              " '187': 60,\n",
              " '119': 60,\n",
              " '208': 60,\n",
              " '111': 60,\n",
              " '79': 60,\n",
              " '151': 60,\n",
              " '133': 60,\n",
              " '103': 60,\n",
              " '112': 60,\n",
              " '85': 60,\n",
              " '44': 60,\n",
              " '188': 60,\n",
              " '150': 60,\n",
              " '78': 60,\n",
              " '23': 60,\n",
              " '113': 60,\n",
              " '77': 60,\n",
              " '154': 60,\n",
              " '43': 60,\n",
              " '225': 60}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have: 4800 train images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'114': 60,\n",
              " '63': 60,\n",
              " '137': 60,\n",
              " '41': 60,\n",
              " '42': 60,\n",
              " '98': 60,\n",
              " '99': 60,\n",
              " '96': 60,\n",
              " '102': 60,\n",
              " '86': 60,\n",
              " '169': 60,\n",
              " '97': 60,\n",
              " '83': 60,\n",
              " '61': 60,\n",
              " '71': 60,\n",
              " '87': 60,\n",
              " '66': 60,\n",
              " '58': 60,\n",
              " '130': 60,\n",
              " '22': 60,\n",
              " '134': 60,\n",
              " '120': 60,\n",
              " '40': 60,\n",
              " '224': 60,\n",
              " '152': 60,\n",
              " '95': 60,\n",
              " '170': 60,\n",
              " '206': 60,\n",
              " '138': 60,\n",
              " '205': 60,\n",
              " '115': 60,\n",
              " '117': 60,\n",
              " '82': 60,\n",
              " '101': 60,\n",
              " '149': 60,\n",
              " '76': 60,\n",
              " '59': 60,\n",
              " '65': 60,\n",
              " '153': 60,\n",
              " '135': 60,\n",
              " '100': 60,\n",
              " '116': 60,\n",
              " '62': 60,\n",
              " '173': 60,\n",
              " '131': 60,\n",
              " '60': 60,\n",
              " '80': 60,\n",
              " '136': 60,\n",
              " '39': 60,\n",
              " '69': 60,\n",
              " '132': 60,\n",
              " '68': 60,\n",
              " '84': 60,\n",
              " '57': 60,\n",
              " '118': 60,\n",
              " '75': 60,\n",
              " '155': 60,\n",
              " '93': 60,\n",
              " '64': 60,\n",
              " '81': 60,\n",
              " '187': 60,\n",
              " '119': 60,\n",
              " '208': 60,\n",
              " '111': 60,\n",
              " '79': 60,\n",
              " '151': 60,\n",
              " '133': 60,\n",
              " '103': 60,\n",
              " '112': 60,\n",
              " '85': 60,\n",
              " '44': 60,\n",
              " '188': 60,\n",
              " '150': 60,\n",
              " '78': 60,\n",
              " '23': 60,\n",
              " '113': 60,\n",
              " '77': 60,\n",
              " '154': 60,\n",
              " '43': 60,\n",
              " '225': 60}"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}